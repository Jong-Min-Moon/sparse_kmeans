#!/bin/bash

# Exit immediately if a command exits with a non-zero status.
set -e

# --- Configuration Variables ---
# Base directory for experiments, R scripts, job files, and output files
TABLE_NAME="R_mnist" # A distinct table name for R results
BASE_DIR="/home1/jongminm/sparse_kmeans/experiment/29_08_11_2025/${TABLE_NAME}"
# Path to the SQLite database (for potential future use if results are inserted by bash)
DB_DIR="/home1/jongminm/sparse_kmeans/sparse_kmeans.db"
SUBSAMPLE_SIZE=1000
# --- Simulation Parameters ---
# These variables will define the loops for R simulations
# DIMENSION will be the 'dimension' parameter for the R script (corresponds to N in your original bash loop)
# REP_NUM will be the 'rep_num' parameter for the R script (corresponds to REP in your original bash loop)

# --- Ensure Base Directory Exists ---
# Create the base directory if it doesn't already exist
mkdir -p "$BASE_DIR"
for REP in $(seq 1 30); do
echo "Starting SLURM job generation for R simulations..."
echo "Base Directory: $BASE_DIR"
echo "Database Directory: $DB_DIR (for potential future use)"
echo "Table Name: $TABLE_NAME"

# --- Loop through simulation parameters ---
# Loop for 'REP_NUM' (main repetition number) from 1 to 50
     # Loop for 'DIMENSION' (number of features/dimensions for the R script)
 
        # Define filenames based on current parameters
        RFILE_NAME="${TABLE_NAME}_${REP}" # Name without .R extension
        RFILE="$BASE_DIR/${RFILE_NAME}.R"
        JOBFILE="$BASE_DIR/${RFILE_NAME}.sh"
        OUTFILE="$BASE_DIR/${RFILE_NAME}.out"

 
        # === Create R .R file ===
        # This block writes the R code into the .R file
        cat > "$RFILE" <<EOF
# R script generated by SLURM job generator

# Get parameters from command line arguments
 
# Load libraries and source functions
# IMPORTANT: Ensure these paths are correct and accessible from the compute node.
 library(sparcl)
 library(RSQLite)

source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/competitor.R")
source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/data_generation.R")
source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/get_proportional_subsample.R")


 
# Insert Witten's results into the database
# A helper function to handle the retries
insert_with_retry <- function(conn, table_name, method, accuracy, timing, max_retries = 5, wait_time = 3) {
  retry_count <- 0
  while (retry_count < max_retries) {
    result <- tryCatch({
      sql_query <- paste0("INSERT INTO ", table_name, " (method, accuracy, timing) VALUES (?, ?, ?)")
      dbExecute(conn, sql_query, params = list(method, accuracy, timing))
      return(TRUE) # Success, break the loop
    }, error = function(e) {
      if (grepl("database is locked", e$message, ignore.case = TRUE)) {
        message(paste("Database is locked. Retrying in", wait_time, "seconds..."))
        Sys.sleep(wait_time)
        return(FALSE) # Failure, continue the loop
      } else {
        stop(e) # Re-throw other errors
      }
    })

    if (isTRUE(result)) {
      break
    }
    retry_count <- retry_count + 1
  }
  if (!isTRUE(result)) {
    stop("Failed to insert data after multiple retries.")
  }
}

# Load full dataset (assuming these paths are fixed and accessible from the compute node)
# IMPORTANT: Ensure these CSV files are available on the compute nodes at this exact path.
# If not, you'll need to adjust the paths or copy the files to a shared file system.
x_full <- read.csv("/home1/jongminm/sparse_kmeans/experiment/29_08_11_2025/R_mnist/selected_data_small.csv")
y_full <- read.csv("/home1/jongminm/sparse_kmeans/experiment/29_08_11_2025/R_mnist/selected_labels_small.csv")
y_full= c(y_full\$label)
print(dim(x_full))
print(dim(y_full))
# Initialize sums for accuracy and timing
 


    # Use dimension (from bash) and i (sub-rep) for data generation/subsampling
    # The '45' in your original R code is now 'dimension' from the bash loop
    data = get_proportional_subsample(x_full, y_full, ${SUBSAMPLE_SIZE}, ${REP})

    # Witten's method (sparse_kmeans_ell1_ell2)
    start_time_witten = Sys.time()
    sol_witten = sparse_kmeans_ell1_ell2(data\$X)
    end_time_witten = Sys.time()
    time_witten = as.numeric(end_time_witten - start_time_witten, units="secs")
    accuracy_witten <- evaluate_clustering(sol_witten, data\$y)
 # Now, use the helper function for each method
# Witten's method
 db_name <- '/home1/jongminm/sparse_kmeans/sparse_kmeans.db'
conn <- dbConnect(RSQLite::SQLite(), dbname = db_name)
insert_with_retry(conn, "${TABLE_NAME}", "Witten", accuracy_witten, time_witten)
dbDisconnect(conn)
    # Arias' method (sparse_kmeans_hillclimb)
    start_time_arias = Sys.time()
    sol_arias = sparse_kmeans_hillclimb(data\$X)
    end_time_arias = Sys.time()
    time_arias  =  as.numeric(end_time_arias - start_time_arias, units="secs")
    accuracy_arias <- evaluate_clustering(sol_arias, data\$y)



 db_name <- '/home1/jongminm/sparse_kmeans/sparse_kmeans.db'
conn <- dbConnect(RSQLite::SQLite(), dbname = db_name)

# Arias' method
insert_with_retry(conn, "${TABLE_NAME}", "Arias", accuracy_arias, time_arias)
dbDisconnect(conn)

# Exit R cleanly after script execution
q("no")
EOF

        # === Create SLURM Job Script (.sh file) ===
        # This block writes the SLURM batch script
        cat > "$JOBFILE" <<EOF
#!/bin/bash
#SBATCH --job-name=R_${TABLE_NAME}  # Job name for easier identification
#SBATCH --output="${OUTFILE}"             # Standard output and error log file
#SBATCH --partition=main                  # Specify the partition to use (e.g., 'main', 'debug')
#SBATCH --nodes=1                         # Request 1 node
#SBATCH --ntasks=1                        # Request 1 task (process)
#SBATCH --cpus-per-task=8                 # Request 4 CPUs per task (adjust based on R's needs)
#SBATCH --mem=8G                          # Request 8 GB of memory (adjust based on data size) 
#SBATCH --time=1:59:59                    # Set maximum job run time (HH:MM:SS)

module purge
module load rstats/4.3.3
cd "$BASE_DIR" || { echo "Error: Could not change to directory $BASE_DIR. Exiting."; exit 1; }

# Run the R script in batch mode
# Pass DIMENSION and REP_NUM as command-line arguments to the R script
Rscript "${RFILE_NAME}.R"    

# Echo end time for logging
echo "Finished R job at \$(date)"
EOF

        # === Submit SLURM Job ===
        # Submit the generated job script to the SLURM scheduler
        echo "Submitting job: $JOBFILE"
        sbatch "$JOBFILE"

        # Pause for 1 second to avoid overwhelming the SLURM scheduler
        sleep 1

done # for loop for REP
echo "All SLURM R jobs have been generated and submitted."