# R script generated by SLURM job generator

# Get parameters from command line arguments
 
# Load libraries and source functions
# IMPORTANT: Ensure these paths are correct and accessible from the compute node.
 library(sparcl)
 library(RSQLite)

source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/competitor.R")
source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/data_generation.R")
source("/home1/jongminm/sparse_kmeans/experiment/25_04_03_2025/get_proportional_subsample.R")


 
# Insert Witten's results into the database
# A helper function to handle the retries
insert_with_retry <- function(conn, table_name, method, accuracy, timing, max_retries = 5, wait_time = 3) {
  retry_count <- 0
  while (retry_count < max_retries) {
    result <- tryCatch({
      sql_query <- paste0("INSERT INTO ", table_name, " (method, accuracy, timing) VALUES (?, ?, ?)")
      dbExecute(conn, sql_query, params = list(method, accuracy, timing))
      return(TRUE) # Success, break the loop
    }, error = function(e) {
      if (grepl("database is locked", e, ignore.case = TRUE)) {
        message(paste("Database is locked. Retrying in", wait_time, "seconds..."))
        Sys.sleep(wait_time)
        return(FALSE) # Failure, continue the loop
      } else {
        stop(e) # Re-throw other errors
      }
    })

    if (isTRUE(result)) {
      break
    }
    retry_count <- retry_count + 1
  }
  if (!isTRUE(result)) {
    stop("Failed to insert data after multiple retries.")
  }
}

# Load full dataset (assuming these paths are fixed and accessible from the compute node)
# IMPORTANT: Ensure these CSV files are available on the compute nodes at this exact path.
# If not, you'll need to adjust the paths or copy the files to a shared file system.
x_full <- read.csv("/home1/jongminm/sparse_kmeans/experiment/29_08_11_2025/R_mnist/selected_data_small.csv")
y_full <- read.csv("/home1/jongminm/sparse_kmeans/experiment/29_08_11_2025/R_mnist/selected_labels_small.csv")
y_full= c(y_full$label)
print(dim(x_full))
print(dim(y_full))
# Initialize sums for accuracy and timing
 


    # Use dimension (from bash) and i (sub-rep) for data generation/subsampling
    # The '45' in your original R code is now 'dimension' from the bash loop
    data = get_proportional_subsample(x_full, y_full, 1000, 12)

    # Witten's method (sparse_kmeans_ell1_ell2)
    start_time_witten = Sys.time()
    sol_witten = sparse_kmeans_ell1_ell2(data$X)
    end_time_witten = Sys.time()
    time_witten = as.numeric(end_time_witten - start_time_witten, units="secs")
    accuracy_witten <- evaluate_clustering(sol_witten, data$y)
 # Now, use the helper function for each method
# Witten's method
 db_name <- '/home1/jongminm/sparse_kmeans/sparse_kmeans.db'
conn <- dbConnect(RSQLite::SQLite(), dbname = db_name)
insert_with_retry(conn, "R_mnist", "Witten", accuracy_witten, time_witten)
dbDisconnect(conn)
    # Arias' method (sparse_kmeans_hillclimb)
    start_time_arias = Sys.time()
    sol_arias = sparse_kmeans_hillclimb(data$X)
    end_time_arias = Sys.time()
    time_arias  =  as.numeric(end_time_arias - start_time_arias, units="secs")
    accuracy_arias <- evaluate_clustering(sol_arias, data$y)



 db_name <- '/home1/jongminm/sparse_kmeans/sparse_kmeans.db'
conn <- dbConnect(RSQLite::SQLite(), dbname = db_name)

# Arias' method
insert_with_retry(conn, "R_mnist", "Arias", accuracy_arias, time_arias)
dbDisconnect(conn)

# Exit R cleanly after script execution
q("no")
